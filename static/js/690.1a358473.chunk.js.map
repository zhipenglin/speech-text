{"version":3,"file":"static/js/690.1a358473.chunk.js","mappings":"8MAGA,MCH2D,GAAgBA,WDGtD,CACjBC,KAAM,cACNC,QAAS,yIAKTC,YAAa,8BACbC,IAAK,u4FAwHLC,QAAS,CACLC,QAAQ,EACRC,UAAW,oBACXC,MAAO,oGAKPC,KAAM,CAAC,CACXC,MAAO,mDACPC,YAAa,mDACbC,KAAM,+oDAsCNC,MAAO,CAAC,CACRZ,KAAM,cACNE,YAAa,+BACbW,gBAAiB,6DACjBC,UAAW,GACb,CACEd,KAAM,OACNE,YAAa,OACbY,UAAW,KAEb,CACEL,MAAO,uCACPC,YAAa,uCACbC,KAAM,q0EA4DNC,MAAO,CAAC,CACRZ,KAAM,cACNE,YAAa,+BACbW,gBAAiB,6DACjBC,UAAW,GACb,CACEd,KAAM,OACNE,YAAa,OACbY,UAAW,GACb,CACEd,KAAM,SACNE,YAAa,QACbY,U,eCxQSC,EAAW,CAAC,KAAO,cAAc,QAAU,QAAQ,gBAAe,EAAK,aAAa,eAAe,QAAU,CAAC,CAAC,KAAO,cAAc,QAAU,4CAA4C,YAAc,GAAG,YAAc,gC","sources":["../../README.md","../node_modules/readme/modules.js"],"sourcesContent":["import * as component_1 from '@kne/current-lib_speech-text';\nimport * as component_2 from 'antd';\nimport * as component_3 from 'axios';\nconst readmeConfig = {\n    name: `speech-text`,\n    summary: `<h1>speech-text</h1>\n<h3>安装</h3>\n<pre><code class=\"language-shell\">npm i --save @kne-components/speech-text\n</code></pre>`,\n    \n    packageName: `@kne-components/speech-text`,\n    api: `<h4>默认导出 speech(options):Promise</h4>\n<p>上传语音文件识别</p>\n<p>example:</p>\n<pre><code class=\"language-javascript\">const {start, stop} = await speech(options);\n</code></pre>\n<h4>options:Object</h4>\n<table>\n<thead>\n<tr>\n<th>属性名</th>\n<th>说明</th>\n<th>类型</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>url</td>\n<td>上传文件语音识别目标接口地址</td>\n<td>string</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<h4>开始录音 start():Promise</h4>\n<p>example:</p>\n<pre><code class=\"language-javascript\">await start();\n</code></pre>\n<h4>结束录音 stop():Promise</h4>\n<p>example:</p>\n<pre><code class=\"language-javascript\">const response = await stop();\nconst {code, message} = response.data;\n</code></pre>\n<table>\n<thead>\n<tr>\n<th>属性名</th>\n<th>说明</th>\n<th>类型</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>code</td>\n<td>后端接口返回状态值,200为成功</td>\n<td>number</td>\n<td>-</td>\n</tr>\n<tr>\n<td>message</td>\n<td>语音转换结果</td>\n<td>string</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<h3>speechTextRealTime(options):Promise</h3>\n<p>实时语音识别</p>\n<p>example:</p>\n<pre><code class=\"language-javascript\">const {start, stop} = await speechTextRealTime(options);\n</code></pre>\n<h4>options:Object</h4>\n<table>\n<thead>\n<tr>\n<th>属性名</th>\n<th>说明</th>\n<th>类型</th>\n<th>默认值</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>getToken</td>\n<td>获取Token方法:getToken():{token,appKey}</td>\n<td>function</td>\n<td>-</td>\n</tr>\n<tr>\n<td>onChange</td>\n<td>识别文本内容发生变化时回调函数</td>\n<td>function</td>\n<td>({message}) =&gt; {console.log(message);}</td>\n</tr>\n<tr>\n<td>getGatewayUrl</td>\n<td>获取WebSocket的url地址: getGatewayUrl({token}):url,可以获取到token参数</td>\n<td>function</td>\n<td>-</td>\n</tr>\n<tr>\n<td>onComplete</td>\n<td>录音结束回调方法</td>\n<td>function</td>\n<td>-</td>\n</tr>\n<tr>\n<td>url</td>\n<td>保存录音文件url</td>\n<td>string</td>\n<td>-</td>\n</tr>\n</tbody>\n</table>\n<h4>开始录音 start():Promise</h4>\n<p>example:</p>\n<pre><code class=\"language-javascript\">await start({\n    getToken: () =&gt; {\n    },\n    onChange: ({message}) =&gt; {\n    },\n    onComplete: ({file, taskId, messageId, message, chunks}) =&gt; {\n    }\n});\n</code></pre>\n<h4>结束录音 stop():Promise</h4>\n<p>example:</p>\n<pre><code class=\"language-javascript\">await stop();\n</code></pre>`,\n    example: {\n        isFull: true,\n        className: `speech_text_e4cb6`,\n        style: `.speech_text_e4cb6 .ant-card {\n  border-color: black;\n  text-align: center;\n  width: 200px;\n}`,\n        list: [{\n    title: `录音文件上传识别`,\n    description: `录音文件上传识别`,\n    code: `const {default: speech} = _SpeechText;\nconst {Button, Alert, Flex} = antd;\nconst {useState, useEffect, useRef} = React;\n\nconst BaseExample = () => {\n    const [message, setMessage] = useState({type: 'info', message: '尚未开始'});\n    const [recording, setRecording] = useState(false);\n    const recordRef = useRef(null);\n    useEffect(() => {\n        recordRef.current = speech({url: 'https://ct.deeperagi.com/action/papi/ai/vCMA01/uploadWavFile'});\n    }, []);\n    return <Flex vertical gap={10}>\n        <Alert type={message.type} message={message.message}/>\n        <div>\n            <Button onClick={() => {\n                recordRef.current.then(async ({start, stop}) => {\n                    setMessage({type: 'warning', message: '正在识别，请稍等'});\n                    if (recording) {\n                        const {data} = await stop();\n                        if (data.code === 200) {\n                            setMessage({type: 'success', message: data.message || '未识别到语音内容'});\n                        } else {\n                            setMessage({type: 'error', message: '转换错误'});\n                        }\n                    } else {\n                        setMessage({type: 'warning', message: '开始语音识别'});\n                        start();\n                    }\n                    setRecording(!recording);\n                });\n            }}>{recording ? '正在录制' : '点击开始'}</Button>\n        </div>\n    </Flex>;\n};\n\nrender(<BaseExample/>);\n\n`,\n    scope: [{\n    name: \"_SpeechText\",\n    packageName: \"@kne/current-lib_speech-text\",\n    importStatement: \"import * as _SpeechText from \\\"@kne-components/speech-text\\\"\",\n    component: component_1\n},{\n    name: \"antd\",\n    packageName: \"antd\",\n    component: component_2\n}]\n},{\n    title: `实时语音识别`,\n    description: `实时语音识别`,\n    code: `const {speechTextRealTime} = _SpeechText;\nconst {Button, Alert, Flex} = antd;\nconst {default: axios} = _axios;\nconst {useState, useEffect, useRef} = React;\n\nconst BaseExample = () => {\n    const [message, setMessage] = useState({type: 'info', message: '尚未开始'});\n    const [recording, setRecording] = useState(false);\n    const recordRef = useRef(null);\n    useEffect(() => {\n        recordRef.current = speechTextRealTime({\n            getToken: async () => {\n                try {\n                    const {data} = await axios({\n                        url: 'https://ct.deeperagi.com/action/papi/ai/vCMA02/createToken',\n                        method: 'POST',\n                        data: JSON.stringify({\n                            \"avgtype\": \"11111\"\n                        }),\n                        headers: {\n                            'content-type': 'application/json'\n                        }\n                    });\n                    return {\n                        token: data.token, appKey: data.appKey\n                    };\n                } catch (e) {\n                    return {\n                        \"appKey\": \"TYcsiL5CZb9hd9DR\", \"token\": \"e80b7d7f6f054f91a79a14a67cb7f34c\"\n                    };\n                }\n            }, onChange: ({message}) => {\n                setMessage({type: 'success', message});\n            }\n        });\n    }, []);\n\n    return <Flex vertical gap={10}>\n        <Alert type={message.type} message={message.message}/>\n        <div>\n            <Button onClick={() => {\n                recordRef.current.then(async ({start, stop}) => {\n                    setMessage({type: 'warning', message: '正在识别，请稍等'});\n                    if (recording) {\n                        await stop();\n                        setMessage({type: 'info', message: '识别结束'});\n                    } else {\n                        setMessage({type: 'warning', message: '开始语音识别'});\n                        start();\n                    }\n                    setRecording(!recording);\n                });\n            }}>{recording ? '正在录制' : '点击开始'}</Button>\n        </div>\n    </Flex>;\n};\n\nrender(<BaseExample/>);\n\n`,\n    scope: [{\n    name: \"_SpeechText\",\n    packageName: \"@kne/current-lib_speech-text\",\n    importStatement: \"import * as _SpeechText from \\\"@kne-components/speech-text\\\"\",\n    component: component_1\n},{\n    name: \"antd\",\n    packageName: \"antd\",\n    component: component_2\n},{\n    name: \"_axios\",\n    packageName: \"axios\",\n    component: component_3\n}]\n}]\n    }\n};\nexport default readmeConfig;\n","import SpeechText from '@components/speech-text/README.md';export default {SpeechText};\nexport const manifest = {\"name\":\"speech-text\",\"version\":\"1.1.0\",\"open-version\":true,\"public-url\":\"/speech-text\",\"modules\":[{\"name\":\"speech-text\",\"baseDir\":\"/home/runner/work/speech-text/speech-text\",\"description\":\"\",\"packageName\":\"@kne-components/speech-text\"}]};"],"names":["SpeechText","name","summary","packageName","api","example","isFull","className","style","list","title","description","code","scope","importStatement","component","manifest"],"sourceRoot":""}